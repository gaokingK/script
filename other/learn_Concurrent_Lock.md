# 多线程为什么不安全？
- link：https://juejin.cn/post/7175028144812851237#heading-0
- 这是因为我们的程序除了通过共享一段内存之外，每一个 CPU 核心都有它本地的缓存，而 CPU 上的缓存是不共享的，而线程可以同时在不同的 CPU 上执行。CPU 的执行过程是，先从内存中读取数据到 CPU 中，CPU 做完计算再更新到内存中。这样一来，就有可能存在不同线程对同一段内存同时读写的问题。
- 这是什么问题呢？比如，A 线程计算完了但是还没有写回内存的时候，B 线程从内存读取出了 A 线程写入计算结果前的数据，但是按我们的逻辑，B 应该是拿 A 线程的结算结果来进行逻辑运算的，这样就会出现数据不一致了
- ![](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/01e1f01225e24e72aa402f7f7fc05349~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp?)


# 并发控制
- link:
  - https://www.jianshu.com/p/d2ac26ca6525
  - https://blog.csdn.net/qq_34337272/article/details/81072874
- 并发控制
  - 当程序中出现并发的情况下, 需要保证当前用户和其他用户一起操作时, 所得到的结果和单独操作时的结果是一样的.
  - 如果不能保证并发下的数据准确性, 就可能导致脏读/幻读/不可重复读等问题
  - 比如count++在并发环境下是不安全的,可能会出现对数据的操作不幂等
    - 因为count++不是原子操作, 而是三个原子操作的组合
    - 读取内存中的count值赋值给局部变量temp;
    - 执行temp+1操作
    - 将temp值赋值给count
# 锁
- 悲观锁(Pessimistic Concurrency Control)
  - 之所以叫做悲观锁，是因为这是一种对数据的修改持有悲观态度的并发控制方式。总是假设最坏的情况，每次读取数据的时候都默认其他线程会更改数据，因此需要进行加锁操作
  - 修改数据之前先锁定，再修改的方式
  - 具有强烈的独占和排他特性，在整个数据处理过程中，将数据处于锁定状态。
  - 悲观锁的实现，往往依靠数据库提供的锁机制(也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据)。
  - 传统的关系型数据库使用这种锁机制比如行锁、表锁、读锁、写锁等
  - 悲观锁主要实现分为共享锁和排他锁：
    - 共享锁【shared locks】又称为读锁，简称 S 锁。顾名思义，所有的事务只能对其进行读操作不能写操作，加上共享锁后在事务结束之前 其他事务只能再加共享锁，除此之外其他任何类型的锁都不能再加了。（可以加多个）
    - 排他锁【exclusive locks】又称为写锁，简称 X 锁。顾名思义，排他锁就是不能与其他锁并存，如果一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁
    - 不是说锁住之后别的不能操作吗, 那共享锁是咋回事呢?难道不止一把 --------------no
  - 采用的保守策略，为数据处理的安全提供了保证。但是在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会。
  - 另外还会降低并行性，一个事务如果锁定了某行数据，其他事务就必须等待该事务处理完才可以处理那行数据。
  - 悲观锁的实现
    - 需要借助数据库的锁机制
    - 在修改前就尝试去对该记录加上排他锁, 如果加锁失败, 具体响应需要开发者根据实际情况决定是等待还是抛出异常
  - 悲观锁的应用
    - SQL中使用悲观锁
- 乐观锁
  - 乐观锁假设数据一般情况不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果冲突，则返回给用户异常信息，让用户决定如何去做。乐观锁适用于读多写少的场景，这样可以提高程序的吞吐量。
  - 乐观锁采取了更加宽松的加锁机制, 但乐观锁不会刻意使用(是不会使用吧?)数据库本身的锁机制，而是依据数据本身来保证数据的正确性。
  - 乐观锁不会产生死锁 -------------------------no
  - 乐观锁的实现
    - CAS(Compare And Swap) 实现：
      - compare and swap（比较与交换），是一种有名的无锁算法(也叫非阻塞同步（Non-blocking Synchronization)), 是解决多线程并行情况下使用锁造成性能损耗的一种机制。
      - CAS算法设计到三个操作数
        - 需要读写的内存值 V
        - 进行比较的值 A
        - 拟写入的新值 B
        - 写之前把内存中的值读出来为A, 在准备写入之前去用A和V比较, 当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作).
      - 当多个线程需要修改一个变量时, 每个线程都先获取当前的值, 接着走一个原子的CAS操作(可能需要借助硬件级别的机制)
      - 一般情况下是一个自旋操作，即不断的重试。直到成功为止
      - Java 中java.util.concurrent.atomic包下面的原子变量使用了乐观锁的一种 CAS 实现方式。
      - CAS优化 -------------no
        - 如Java8中的新类LongAdder, 它尝试使用分段CAS及自动分段迁移来大幅提高多线程高并发执行CAS操作的性能.
        - 核心思想就是热点分离, 将value值分离成一个数组, 当多线程访问时, 通过hash算法映射到其中的一个数字进行计数, 最终的结果,就是这些数组的求和积累, 这样一来就减小了锁的粒度.

    - 版本号控制 实现(可以解决ABA问题)
      - 一般是在数据表中加上一个数据版本号 version 字段，表示数据被修改的次数。当数据被修改时，version 值会 +1。当线程 A 要更新数据时，在读取数据的同时也会读取 version 值，在提交更新时，若刚才读取到的 version 值与当前数据库中的 version 值相等时才更新，否则重试更新操作，直到更新成功。
      - 如果version不一致, 是自旋还是直接失败呢? -----------------no

  - 乐观锁的缺点
    - ABA问题是乐观锁的一个常见问题
      - 如果另外一个线程修改了变量V, 然后把值又改成了V, 这会使原先的线程认为变量V没有被修改过
    - 循环时间长 开销大
      - 自旋CAS如果长时间不成功, 会给CPU带来非常大的执行开销
      - 处理器提供的pause指令(需要语言支持) 第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。
    - 只能保证一个共享变量的原子操作
      - 当操作设计跨多个共享变量时CAS无效
      - 可以利用锁或者语言提供的类(如JDK中的AtomicReference类)把多个共享变量合并成一个共享变量来操作
- 乐观锁和悲观锁的选择
  - 响应效率: 乐观锁的响应速度高, 且未加锁,效率高
  - 冲突频率: 冲突频率高适合用悲观锁, 因为乐观锁需要多次重试才能成功,代价大
  - 重试代价: 重试代价大的话选择悲观锁,其失败的概率低
  - 乐观锁如果有人在你之前更新了，你的更新应当是被拒绝的，可以让用户从新操作。悲观锁则会等待前一个更新完成。这也是区别
  - 随着三高(高并发, 高可用, 高性能)提出, 悲观锁已经越来越少的应用到生产中了, 特别是并发量大的场景中
### 调度
- CFS 绝对公平算法
### 问题
- 悲观锁,乐观锁会产生死锁吗?
- CAS 在某些情况下能保证原子性吗?
  - A检查完后准备修改,但此刻B把数据改了
  - 比较并交换这个操作, 不是原子性, 即使是底层代码(汇编)也不是(因为可能被其他cpu给打断)
- 语言提供的锁操作是依赖操作系统提供的,操作系统依赖汇编, 汇编有许多种方式, 可以锁缓存, 锁总线(硬件方面, 拉高北桥电平信号)
- 高并发环境下锁粒度把控是一门重要的学问。选择一个好的锁，在保证数据安全的情况下，可以大大提升吞吐率，进而提升性能。