- 简述一个前端请求的处理流程，在uwsgi/nginx/django之间的处理流程
- redis用过哪些数据结构？怎么保存的
- redis为什么快？除了他是内存型数据库外，还有什么原因
- 描述一个东西是什么，可以从他是干什么的，他是怎么产生的，是什么时候出现的，生命周期是怎样等去描述、有什么约束、是怎么实现的
### 
- csrf jwt
- 项目中redis是做什么的
- restful 有什么特点
- 项目是干什么的，有哪些功能
- 自己会部署项目吗
- 写一个项目需要那些
    - 鉴权、接口校验、数据、handler、
- celery用来干啥 定时任务怎么做的
- 跨域怎么解决
- 正向代理反向代理
    - https://cloud.tencent.com/developer/article/1418457
- 都用到 docker 的哪些操作？
- 怎么去管理docker的，是shell侵入式还是docker的api，那技术选型上为什么不选择docker的api
- 还是项目
    - 介绍项目、项目的架构，自己的角色
    - k8s熟悉吗
    - 如何实现CI
- flask 清水池
- having to 子句 ，选择总分第二人的名字、解释下事务、视图、存储流程、游标
- 前端图表组件了解过哪些
- 参与过平台的设计吗？流程图画吗
- 建模语言了解过吗
- 介绍下k8s/docker/jekenis
- python 封装、继承、多态
- 存储引擎的区别
- djano 权限控制
    - https://blog.csdn.net/HHG20171226/article/details/93229831
    - has_perm()s
- 事务的特性
- redis的数据类型、存放排行榜
- python的内存管理
- flask的跨域、路由、django的日志配置
- django 排序 Track.objects.all().order_by('-id','title') - 解决
- new和init的区别 - 解决
- 把列表使用set去重后如何保持顺序和原来一样
- 负载均衡算法
    - https://zhuanlan.zhihu.com/p/68733507
    - 轮询、源地址hash、加权轮询、加权随机、最小连接数法
    - 加权就是根据服务器的负载能力大小分配不同权重，
    - 加权随机就是权重高的选中的概率大
- sqlarchme 分页怎么实现
    - 用offset()设置索引偏移量,limit()限制取出量 `db.session.query(User.name).filter(User.email.like('%'+email+'%')).limit(page_size).offset((page_index-1)*page_size)`
    - 用paginate(偏移量，取出量)函数,用于BaseQuery `user_obj=User.query.filter(User.email.like('%'+email+'%')).paginate(int(page_index), int(page_size),False)`
- GIL锁、GIL锁和互斥锁的区别
    - https://www.cnblogs.com/richardzgt/articles/7761172.html#_label0_3
    - 区别就是颗粒度的大小不同，而依赖CPU计算的线程则是执行代码量到一定的阀值，才会释放GIL
- GIL https://blog.csdn.net/weixin_36440198/article/details/113961683
    - 上面讲到Python在实现Python解析器(CPython)时引入了GIL锁，使得「在一个解释器内，任何时候仅有 一个线程在执行」，Python多线程的效率可能还比不上单线程，那么这个GIL锁是什么？

    - 概念：全局解释器锁，用于同步线程的一种机制，使得任何时候仅有一个线程在执行。GIL 并不是Python的特性，只是在实现Python解析器(CPython)时引入的一个概念。换句话说，Python完全可以不依赖于GIL。Python解释器进程内的多线程是以协同多任务方式执行的，当一个线程遇到I/O操作时会释放GIL,而依赖CPU计算的线程则是执行代码量到一定的阀值，才会释放GIL。

    - 而在Python 3.2开始使用新的GIL，使用固定的超时时间来指示当前线程放弃全局锁，就是：「当前线程持有这个锁，且其他线程请求这个锁时，当前线程就会在5毫秒后被强制释放掉该锁。」多线程在处理CPU密集型操作因为各种循环处理计数等，会很快达到阀值，而**多个线程来回切换是会消耗资源的，所以多线程的效率往往可能还比不上单线程！
    - 如果只有一个进程，那么多核cpu上一个时刻也只有一个线程在运行，而在多核CPU上效率会更低，因为多核环境下，持有锁的CPU释放锁后，其他CPU上的线程都会进行竞争，但GIL可能马上又会被之前的CPU拿到拿到，导致其他几个CPU上被唤醒后的线程会醒着等待到切换时间后又进入待调度状态，从而造成 线程颠簸(thrashing)，导致效率更低。
- 因为GIL锁的原因，对于CPU密集型操作，Python多线程就是鸡肋了？
    - 答：是的！尽管多线程开销小，但却无法利用多核优势！可以使用多进程来规避这个问题，Python提供了multiprocessing这个跨平台的模块来帮助我们实现多进程代码的编写。每个进程都有自己独立的内存空间和解释器，所以每个进程都有独立的GIL，因此不会出现进程间GIL锁抢夺的问题，但是也增加程序实现线程间数据通讯和同步时的成本，这个需要自行进行权衡。
- 如果3核CPU，为了达到最优执行效率，应该开几个进程呢
  - 理论上是可以开启无限个进程的，这取决于操作系统的多任务处理能力和机器的内存大小，操作系统会管理所有进程，并且在多个核心之间分配进程的执行
  - 但是每个进程都需要一定的系统资源，比如内存和处理器时间，如果开启的进程太多，可能会因为资源争抢导致系统性能下降或者不稳定
  - 理想情况下是开启和cpu核数相同的进程，每个进程都不会被调度，但是系统上一定会存在其他的背景进程用来支持操作系统和其他用户程序。

- 线程会在什么时候释放GIL
    - 执行IO操作时，当线程遇到文件读写、网络连接等会阻塞的IO时，会释放GIL，允许其他进程运行
    - 时间片结束后，python多线程中，每个线程会运行固定的时间，然后释放GIL让其他线程运行，这就是协同多任务处理
    - 执行阻塞系统调用，当线程执行系统调用或者其他阻塞操作时，线程也会释放GIL
    - 调用某些外部库，当线程调用某些外部库的函数时，可能会释放GIL
    - 注意释放GIL并不代表会切换到别的线程，仅代表别的线程有可能会拿到GIL，线程调度依赖于系统的调度机制
- 图和树的区别
    - 图没有根节点
- 走象棋
- 进程、线程、协程的区别
    - 协程有点类似于子程序，不过区别在于协程执行的过程中可以中断，执行别的协程
    - 协程和线程的区别
        - 协程的切换是由程序自身控制，没有线程切换的开销，所以有很高的执行效率
        - 不需要线程的锁机制、
    - 多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。
- 进程能占满8个核、线程只能占用一个核
- 进程是系统资源分配的基本单位（可以看成是资源的容器），线程是调度的基本单位。
### 对于cpu密集型的任务，使用python的协程可以提高效率吗
协程主要是用于处理I/O密集型任务，它们通过在I/O操作（如网络请求或读写文件操作等）时进行任务切换来提升效率，而对于CPU密集型任务，这种方式的提升是有限的。
在CPU密集型任务中，主要的瓶颈是CPU处理能力。Python的协程（尤其是在asyncio库中）运行在单个线程中，意味着同一时间只有一段代码在执行。即使你使用了异步编程模型，CPU密集型任务也会阻塞事件循环，因此不会提升效率。换句话说，协程并不能将单个CPU密集型任务分发到多个CPU核心上，它们不会提供并行处理的好处。
如果需要提高CPU密集型任务的效率，你可以考虑以下选项：
多进程: Python的multiprocessing模块能够创建进程池并利用多CPU核心的优势来并行处理任务。
改用更适合的语言: 对于CPU密集型任务，使用能够编译为机器码的语言（如C或Go）可能会更有效率，因为Python在运行时有全局解释器锁（GIL）的限制。
优化算法: 无论使用哪种编程语言或并发模型，优化算法总是提高性能的有效手段。
并行计算库: 利用诸如Numpy这类的库，它们在内部对某些操作进行了优化并可使用多线程进行处理。
外部服务: 有时候把CPU密集型任务外包给专门的服务或工具，比如通过API调用AI模型、数据库查询优化等，这样也能提高处理效率。
简而言之，在处理CPU密集型任务时，协程并不是一个提升效率的好选择。你应该寻找其他并发和并行解决方案。
### 协程和异步有什么区别
"协程"（Coroutine）和"异步"（Asynchronous）是相关联的概念，它们在现代编程中都用于提高应用程序处理多任务的效率。它们之间的区别通常涉及这些概念的使用和实现。下面我们分别解释这两个概念，并描述它们之间的关系和区别：

### 协程（Coroutine）
协程是一种程序组件，它允许多个入口点用于暂停和恢复执行，可以在单线程中实现多任务的并发。协程比线程更轻量，它们的创建和切换开销小得多，并且它们的执行不是通过操作系统管理，而是完全由应用程序控制。在编程语言中，协程通常由特定的关键字（如`yield`, `await`）和库（如Python中的`asyncio`）支持。协程极大地简化了编写非阻塞代码的难度，并允许程序员用一种顺序的方式编写并发程序。

### 异步（Asynchronous）
异步编程是一种范式，它使得程序可以启动一个操作并继续执行而不等待这个操作完成。异步的概念可以用在多种编程范式中，包括回调函数、事件循环、Promise/任务，以及上面提到的协程。异步操作通常与I/O密集型活动相关联，比如网络请求、文件操作等，这些操作不需要持续使用CPU进行计算，程序可以在等待结果的过程中去处理其他任务。

### 两者之间的关系和区别
- **关系**: 协程常常是实现异步编程的一个强大工具。一个异步操作可以在协程中启动，在等待操作完成的同时，协程的控制器（如Python中的事件循环）可以切换到其他协程执行其他任务。在异步编程中，协程提供了一种避免深层嵌套的回调和复杂状态管理的方式，从而使异步代码更易于读写和维护。当协程等待异步操作的结果时，它们会被挂起，这允许系统运行其他协程，直到结果可用。
  
- **区别**: "异步"描述了一种概念或编程模型，即函数或任务的非阻塞执行，而"协程"则是这种模型的一种实现方式。回调函数也可以用于实现异步行为，但它们可以变得复杂且难以管理，尤其是在涉及多个异步操作时（所谓的“回调地狱”）。而协程提供了一种更为直接的方式来编写和维护异步代码，通过让代码呈现出顺序执行的形态。

总结起来，协程是实现异步编程的工具之一，而异步编程本身是一种范式，它定义了函数或任务的执行方式，即允许非阻塞和并行的任务执行。协程让异步代码的书写更具可读性和维护性。当你在处理多个并发任务时，尤其是在I/O操作时，协程和异步编程都是提高效率的重要手段。
- flask 获取getpost参数
- mysql支持范围查询吗
- a="xxx" a[0]="2"不可以
- 索引的最左匹配

- top 显示某个用户的 -u
- 类的继承方式
- 析构 del
- 偏函数
    - 把函数的某些参数给固定住
- lambda 缺点
    - 不能在其他地方引用
- 创建索引的过程中可以插入数据吗
    - 可以这样回答，我没在创建索引的过程中插入过数据，但感觉创建索引的过程中是不会锁表的吧
- 数据库的4种隔离级别 幻读是什么
- int可以做dict的键吗？ 可以
- 软连接和硬链接的区别
- 用户权限777
- 训练集、测试集、验证集
- 缓存穿透、缓存雪崩和缓存击穿是与缓存系统相关的三种不同问题，它们都可能导致缓存的失效或性能下降。
- 缓存穿透和缓存击穿的区别在于前者找的数据哪里都不存在，后者找的数据只是在缓存里不存在
1. **缓存穿透（Cache Penetration）**：
   - **问题描述**：缓存穿透是指恶意或非常频繁地查询一个在缓存中不存在的数据，导致每次查询都落在数据库上，从而增加了数据库的负担。
   - **原因**：通常由于查询一个不存在的数据，而缓存不会命中，因此每次请求都会穿透到底层数据存储。
   - **解决方法**：可以在查询之前添加一些预处理，例如布隆过滤器（Bloom Filter）来过滤掉无效的查询请求，或者缓存空值以减轻数据库负载。

2. **缓存雪崩（Cache Avalanche）**：
   - **问题描述**：缓存雪崩是指缓存中的多个缓存项在大约相同的时间内失效或被清除，导致大量请求同时击中底层数据存储，引发系统性能问题。
   - **原因**：通常是由于多个缓存项设置了相同的过期时间，或者缓存服务器出现故障，导致缓存项一起失效。
   - **解决方法**：避免设置相同的过期时间，采用随机的过期时间分散缓存项的失效时间，以减少缓存项同时失效的可能性。此外，使用缓存高可用性解决方案来防止缓存服务器单点故障。

3. **缓存击穿（Cache Miss）**：
   - **问题描述**：缓存击穿是指一个缓存中不存在但在底层数据存储中存在的数据项被大量请求，导致大量的请求直接击中底层数据存储，增加了其负担。
   - **原因**：通常是由于某个热门数据项的缓存过期，而大量请求同时到达，导致缓存无法命中。
   - **解决方法**：可以采用互斥锁或分布式锁来控制多个请求同时查询缓存中不存在的数据项，以避免同时触发多次数据库查询。

为了有效地处理这些问题，通常需要综合考虑缓存策略、过期时间的随机化、缓存监控和高可用性等多种方法。不同的应用场景和需求可能需要不同的解决方案。

### 用户在浏览器里输入网址到看到页面加载效果，这个过程中都发生了什么
- 解析URL:
浏览器会分析输入的URL，分辨出协议（如 http 或 https）、服务器（域名）及可能的资源路径（如 /index.html）。
- DNS查询:
浏览器需要解析域名为IP地址。如果这个信息没有缓存，浏览器会向一个DNS服务器发送请求来找出与给定域名匹配的IP地址。
- 建立连接:
浏览器通过找到的IP地址与目标服务器建立TCP连接。对于HTTPS连接，还会进行一个TLS握手过程，以建立一个安全的连接。
- 发送HTTP请求:
浏览器向服务器发送一个HTTP请求。该请求包含了请求类型（如 GET）、所请求资源的路径、协议版本以及可能包含的额外的请求头信息。
服务器处理请求:
服务器接收到请求后，会进行处理，这可能包括在数据库中查找数据、进行服务器端计算等操作。
服务器响应:
服务器处理完请求后，将响应发送回浏览器。这通常是一个包含HTML内容的HTTP响应，其中也包含了状态码（如200 OK表示成功）以及响应头信息。
加载HTML内容:
浏览器开始读取、解析返回的HTML内容，并根据需要发起新的请求，比如请求CSS文件、JavaScript文件以及页面中的其他资源（如图片、视频等）。
渲染页面:
当浏览器接收到资源文件后，会开始渲染页面。CSS规则会被应用，JavaScript会被执行，这可能会影响页面的内容和布局。
执行JavaScript:
如果页面中包含JavaScript，浏览器还会执行它们。JavaScript可以动态修改DOM（文档对象模型）和CSSOM（CSS对象模型），并可能触发额外的HTTP请求。
最终显示:
在所有资源加载且JavaScript执行（如果有）之后，浏览器会显示最终的页面。这时用户可以看到完整的页面，并与其交互。
这整个过程可以被非常高级地概括为地址解析、请求/应答、资源加载和页面渲染几个大步骤，但实际上每个步骤背后都有复杂的过程和技术细节。此外，现代网页的加载过程中还涉及到了对性能优化的考虑，如资源压缩、缓存、CDN使用等。
### 如果后端是使用flask实现的前后端分离项目，从收到请求到返回请求，这中间又发生了什么呢 
当后端使用 Flask 实现的前后端分离项目收到请求后，以下是这个过程中可能发生的一系列步骤：
Web服务器处理:
最初的HTTP请求由Web服务器（例如Nginx或Apache）接收。如果请求是HTTPS请求，Web服务器还负责处理TLS握手。
Web服务器根据配置决定如何处理请求。对于通过uWSGI或Gunicorn等WSGI服务器运行的Flask应用程序，Web服务器将请求转发给WSGI服务器。
WSGI服务器:
WSGI服务器是Web服务器和Flask应用之间的中间层。它将HTTP请求转化为WSGI环境并调用Flask应用。
Flask请求处理:
Flask框架接收到WSGI服务器传递的请求，并开始处理它。
Flask会根据注册的URL路由器（规则）确定哪个视图函数应该处理请求。
Flask支持请求预处理，可以通过钩子（如 @before_request）进行用户认证、请求日志记录等操作。
视图函数处理:
Flask确定后，相应的视图函数（控制器）被调用。这个函数将处理业务逻辑并准备响应数据。
数据库和服务层:
视图函数可能会与数据库交互来检索、更新或删除数据。这可能涉及到ORM（对象关系映射器）如SQLAlchemy。
如果有复杂的业务逻辑，可能会调用服务层或其他内部API来处理数据。
视图函数还可以调用外部API，如第三方服务或微服务。
构造响应:
业务逻辑处理完毕后，视图函数将生成一个响应对象。这通常包括状态码、响应头，以及JSON、HTML或其他数据格式的响应体。
Flask响应后处理:
Flask提供响应后处理的钩子，通过@after_request修饰器可以在响应发送到客户端之前修改响应对象。
应用可能在此步骤设置响应头，如CORS（跨源资源共享）头部。
响应返回:
WSGI服务器获取到Flask创建的响应对象并通过HTTP协议将它发送回Web服务器。
Web服务器则将响应返回给客户端浏览器。
同样，整个流程是高度抽象的，且在实践中会根据不同项目的架构和需求而有所变化。例如，它可能涉及到缓存策略、消息队列、异步操作等高级特性。而且，不同项目的错误处理、日志记录和安全保护措施也会导致处理流程有细微的差别。

# 既然wsgi也支持多进程和多线程，并且可以通过这些技术来提高并发，那么为什么还会出现Asgi呢
WSGI (Web Server Gateway Interface) 是 Python 中使用广泛的 Web 服务器与应用程序之间的标准接口，其设计目标是为了促进简单的同步应用程序的开发。然而，随着 Web 应用程序的复杂性增加和实时通信的需求升高（例如，WebSocket、HTTP/2），WSGI 显示出了一些局限性。这是因为 WSGI 设计时主要关注同步处理请求，它在处理异步协议和长连接等场景时相对较为笨重。为了解决这些局限性和更好地支持现代 Web 应用程序的需求，ASGI (Asynchronous Server Gateway Interface) 出现了。
ASGI 的主要优势包括：
异步支持：ASGI 为异步和同步应用程序提供了原生支持。这意味着它可以同时处理大量连接，非常适合实时数据处理和高并发场景，如聊天应用和实时通知。
更好的资源利用：借助异步编程，单个线程可以同时处理多个请求，从而提高了资源利用率，减少了服务器负载。
灵活性：ASGI 提供了一种能够支持 WebSocket 和 HTTP/2 等现代 Web 技术的解决方案，以及传统的 HTTP 请求/响应。这种灵活性使得开发者能够创建更富交互性、更高性能的应用程序。
向后兼容WSGI：ASGI 应用程序可以包含 WSGI 应用程序，这样就能同时运行新的异步代码和现有的同步代码。这提供了一个平稳迁移的路径，无需重写现有应用程序。
社区推动的创新：随着异步编程在 Python 社区中的日益流行，ASGI 提供了一种标准化的方式来利用这些新技术。社区成员可以贡献中间件、框架和工具，以支持更广泛的用例和集成。
总而言之，ASGI 的出现是为了满足现代 Web 应用对异步处理和高并发的需求，它代表了 Python Web 开发向更高效、灵活和现代化方向的进步。
### python字典底层使用的是什么数据结构呢？怎么解决哈希碰撞的问题
- Python 字典（dict）是一种高度优化的数据结构，其底层实现使用了哈希表（hash table）。哈希表是一种以键-值对（key-value pair）存储数据的数据结构，通过散列函数将键映射到对应的存储位置。以下是一些关于 Python 字典底层实现和哈希碰撞解决方法的详细信息。
- Python 字典的底层数据结构
- Python 字典的实现通过 C 语言在 CPython 中完成，其底层主要使用了哈希表和动态数组。哈希表中的每个元素称为桶（bucket），每个桶存储键-值对。哈希表具有以下几个关键特点：
- 哈希函数：
Python 使用内置的哈希函数 hash() 来计算每个键的哈希值，从而将键映射到哈希表中的一个位置（索引）。
- 动态扩展：
当哈希表达到一定负载因子时（load factor，即表中存储的元素数量与哈希表大小的比值），哈希表会自动扩展，以减少哈希碰撞，并提高查询和插入效率。这一过程称为 rehashing（重新哈希）。
- 解决哈希碰撞的方法
哈希碰撞是指不同的键在经过哈希函数计算后，映射到相同的哈希表位置。Python 字典使用 开放地址法（open addressing） 来解决哈希碰撞问题，具体采用了二次探测（quadratic probing）的策略。
- 开放地址法（Open Addressing）
当发生碰撞时，Python 字典会在哈希表中寻找下一个可用的桶，而不是将多个元素链入同一个桶。
重哈希的规则是哈希值加上二次探测步长，这样做有助于减少聚簇效应（clustering effect）。
- 具体的探测步骤如下：
- 计算键的哈希值。
- 如果目标桶已经被占用，计算新的索引位置，通过步骤 3 来避免连续探测产生的大量聚簇。
- 使用二次探测公式：new_index = original_index + step^2，其中 step 是当前探测次数，从 1 开始递增。
- 哈希表的其他考虑
- 负载因子和扩容：
- 当负载因子超过某个阈值时（通常为 2/3 左右），哈希表会进行扩容。扩容时，哈希表的大小通常会翻倍，并重新计算所有元素的新位置。
- 删除元素：
删除操作并不是简单地将桶置为空，因为这样可能会破坏探测序列（如果有一个值A哈希到了一个已经有值的位置会重新哈希，那么当这个值删掉置空时，查找A时会找到这个空位置）。Python 字典使用一个特殊的标记（dummy value）来标识被删除的元素位置。
# python字典和列表取值的时间复杂度是多少呢
- 需要提高 Python 的效率，使用适当的数据结构很重要。对于需要频繁查找、插入和删除操作的场景，字典（哈希表）无疑是最佳选择；对于需要保持有序数据或频繁通过索引访问的场景，列表（动态数组）更为合适
- 字典（Dict）:
取值：平均 O(1)
插入：平均 O(1)
删除：平均 O(1)
- 最坏的时间复杂度都是O(n) 最坏情况下的时间复杂度：O(n)，但这种情况在实践中极为罕见，通常发生在哈希碰撞非常严重的情况下。
- 列表（List）:
取值：O(1)（按索引）
插入：O(1) 末尾, 插入 O(n) 开头或中间 因为要将后面的元素都后移一位
删除：O(1) 末尾, 删除 O(n) 开头或中间

# 怎么做到线程状态的隔离，协程怎么做隔离？有没有什么轻量级的方法，python内置的？
在 Python 中，实现线程状态和协程状态的隔离是确保并行和并发编程中数据一致性和安全性的关键。以下是实现这些隔离的几种方法：

### 线程状态的隔离

#### 1. 使用 `threading.local()`
Python 提供了 `threading.local()` 类，这使得每个线程都有其独立的状态。我们可以将需要隔离的状态绑定到 `threading.local()` 对象上，使每个线程拥有独立的这些变量。

示例代码：
```python
import threading

# 创建一个线程本地数据对象
local_data = threading.local()

def worker():
    # 每个线程都设置自己的 local_data 属性
    local_data.some_data = threading.current_thread().name
    print(f'Thread {threading.current_thread().name} has data: {local_data.some_data}')

# 创建并启动多个线程
threads = []
for i in range(5):
    t = threading.Thread(target=worker)
    threads.append(t)
    t.start()

for t in threads:
    t.join()
```

#### 2. 使用锁（Lock）
对于共享资源的访问，使用锁（`threading.Lock`）来确保同一时间只有一个线程能访问该资源，从而保证数据的一致性和正确性。

示例代码：
```python
import threading

counter = 0
lock = threading.Lock()

def increment():
    global counter
    with lock:
        local_counter = counter
        local_counter += 1
        counter = local_counter

threads = []
for i in range(5):
    t = threading.Thread(target=increment)
    threads.append(t)
    t.start()

for t in threads:
    t.join()

print(f'Final counter value: {counter}')
```

### 协程状态的隔离

#### 1. 使用 `contextvars` 模块
Python 3.7 引入了 `contextvars` 模块，这个模块提供了协程状态隔离的能力，可以在不同的协程中使用独立的上下文变量。

示例代码：
```python
import asyncio
import contextvars

# 创建一个上下文变量
var = contextvars.ContextVar('var', default='default')

async def worker(value):
    # 设置上下文变量的值
    var.set(value)
    print(f'Coroutine {value}, var value: {var.get()}')
    await asyncio.sleep(1)
    print(f'Coroutine {value}, var value after sleep: {var.get()}')

async def main():
    await asyncio.gather(
        worker('A'),
        worker('B'),
    )

asyncio.run(main())
```

#### 2. 使用 Task Local 存储
异步库如 `asyncio` 本身就支持任务本地存储，虽然不像线程本地存储那么直接，但可以通过上下文变量来实现。

示例代码：
```python
import asyncio

# 创建一个任务本地数据存储字典
task_data = {}

async def worker(value):
    task_data[asyncio.current_task()] = value
    print(f'Coroutine {value}, data: {task_data[asyncio.current_task()]}')
    await asyncio.sleep(1)
    print(f'Coroutine {value}, data after sleep: {task_data[asyncio.current_task()]}')

async def main():
    await asyncio.gather(
        worker('A'),
        worker('B'),
    )

asyncio.run(main())
```

### 轻量级方法和内置支持
- `threading.local()` 和 `contextvars` 是 Python 内置的轻量级方法，可以有效隔离线程和协程状态。
- 对于线程隔离，可以使用 `threading.Lock` 等同步原语来保障资源访问安全。
- 对于协程隔离，使用 `contextvars.ContextVar` 进行上下文变量的隔离是最灵活和推荐的方式。

这些方法不需要第三方库，直接利用 Python 标准库提供的工具就可以实现线程和协程状态的隔离。总之，根据不同的使用场景，选择合适的状态隔离技术可以显著提升并发代码的安全性和可维护性。
